# Domain-Driven Architecture Implementation

## ğŸ¯ **Why Create Interfaces in Domain?**

**YES!** Creating interfaces in your domain that infrastructure must follow is an excellent architectural practice. Here's why:

### âœ… **Benefits of Domain Interfaces:**

1. **ğŸ”’ Dependency Inversion Principle**: Domain defines contracts, infrastructure implements them
2. **ğŸ§ª Testability**: Easy to mock interfaces for unit testing
3. **ğŸ”„ Flexibility**: Swap implementations (CSV â†’ Database â†’ API) without changing business logic  
4. **ğŸ¯ Clean Separation**: Business logic stays pure, technical concerns stay in infrastructure
5. **ğŸ“ SOLID Principles**: Follows Interface Segregation and Dependency Inversion
6. **ğŸš€ Maintainability**: Changes to infrastructure don't affect domain logic

---

## ğŸ—ï¸ **New Architecture Overview**

### **Domain Layer** (`src/domain/`)
- **`shipment.py`**: Core business entity with calculated fields and business rules
- **`interfaces/`**: Contracts that infrastructure must implement
  - **`repository.py`**: Data access contracts (ShipmentRepository)
  - **`storage.py`**: File storage contracts (FileStorageService)
  - **`validator.py`**: Data validation contracts (DataValidator)
  - **`notification.py`**: Notification contracts (NotificationService)
  - **`metrics.py`**: Metrics collection contracts (MetricsCollector)
- **`services/`**: Business logic orchestration using interfaces
  - **`etl_service.py`**: ETL pipeline orchestration (ShipmentETLService)
  - **`analytics_service.py`**: Business intelligence (ShipmentAnalyticsService)

### **Infrastructure Layer** (`src/infra/adapters/`)
- **`s3_storage_adapter.py`**: S3 implementation of FileStorageService
- **`csv_repository_adapter.py`**: CSV implementation of ShipmentRepository
- **`pandera_validator_adapter.py`**: Pandera implementation of DataValidator
- **`console_notification_adapter.py`**: Console implementation of NotificationService
- **`simple_metrics_adapter.py`**: Simple implementation of MetricsCollector
- **`s3_adapter.py`**: Legacy adapter (can be removed now)

### **Application Layer** (`src/app/`)
- **`cli.py`**: Dependency injection and orchestration
- **`config.py`**: Configuration management

---

## ğŸ”Œ **Domain Interfaces Created:**

### 1. **`ShipmentRepository`**
```python
- extract_shipments(source_path) â†’ List[Dict]
- save_shipments(shipments, destination) â†’ bool
```
**Purpose**: Data access abstraction

### 2. **`FileStorageService`**
```python
- upload_file(local_path, remote_key, bucket) â†’ bool
- download_file(remote_key, bucket, local_path) â†’ bool
- list_files(bucket, prefix) â†’ List[str]
- create_bucket(bucket) â†’ bool
```
**Purpose**: File storage operations

### 3. **`DataValidator`**
```python
- validate_shipments(shipments) â†’ (valid_shipments, errors)
- validate_dataframe(df) â†’ (valid_df, errors)
```
**Purpose**: Data validation abstraction

### 4. **`NotificationService`** (Optional)
```python
- notify_success(message, details) â†’ bool
- notify_error(message, error_details) â†’ bool
- notify_warning(message, warning_details) â†’ bool
```
**Purpose**: Communication abstraction

### 5. **`MetricsCollector`** (Optional)
```python
- record_pipeline_run(records, time, success)
- record_business_metrics(shipments)
- record_data_quality_metrics(total, valid, errors)
```
**Purpose**: Observability abstraction

---

## ğŸ¯ **Domain Services**

### **`ShipmentETLService`**
- **Purpose**: Orchestrates the entire ETL pipeline using interfaces
- **Dependencies**: Repository, Storage, Validator, Notifications (optional), Metrics (optional)
- **Benefits**: Pure business logic, fully testable, infrastructure-agnostic

### **`ShipmentAnalyticsService`**
- **Purpose**: Business analytics and insights
- **Features**: Route profitability analysis, optimization opportunities

---

## ğŸ”„ **How It All Works Together**

```python
# 1. Create infrastructure implementations
storage_service = S3StorageAdapter(s3_client)
repository = CSVShipmentRepository(storage_service)
validator = PanderaDataValidator()

# 2. Inject into domain service
etl_service = ShipmentETLService(
    repository=repository,
    storage_service=storage_service,
    validator=validator
)

# 3. Run business logic
result = etl_service.process_shipments(source_path, bucket)
```

---

## ğŸ§ª **Testing Benefits**

```python
# Easy mocking for unit tests
mock_repo = Mock(spec=ShipmentRepository)
mock_storage = Mock(spec=FileStorageService)
mock_validator = Mock(spec=DataValidator)

etl_service = ShipmentETLService(mock_repo, mock_storage, mock_validator)
# Test pure business logic without infrastructure dependencies!
```

---

## ğŸ”„ **Easy Implementation Swapping**

Want to switch from CSV to PostgreSQL?
```python
# Just change the repository implementation
repository = PostgreSQLShipmentRepository(db_connection)
# Everything else stays the same!
```

Want to add email notifications?
```python
notification_service = EmailNotificationService(smtp_config)
etl_service = ShipmentETLService(
    repository, storage, validator, 
    notification_service=notification_service  # Just add it!
)
```

---

## ğŸ¯ **Key Architectural Benefits**

1. **ğŸ§ª Fully Testable**: Mock interfaces for unit testing
2. **ğŸ”„ Swappable Components**: Change implementations without changing business logic
3. **ğŸ“ SOLID Principles**: Clean architecture following best practices
4. **ğŸ¯ Separation of Concerns**: Domain logic separate from technical details
5. **ğŸš€ Maintainable**: Changes are isolated and predictable
6. **ğŸ“Š Rich Business Logic**: Domain services provide business insights
7. **ğŸ”’ Type Safety**: Interfaces define clear contracts

Your ETL pipeline is now following **Domain-Driven Design** principles with clean architecture! ğŸ‰
